{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import preprocessing\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('notebook_env.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Blight', 'Healthy', 'Mildew', 'Rust', 'Spot']\n",
    "img_size = 224\n",
    "def get_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets/Train\\\\Blight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/Train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m val \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/Validation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m x_train \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn [4], line 8\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, label)\n\u001b[0;32m      7\u001b[0m class_num \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mindex(label)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         img_arr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, img))[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m#convert BGR to RGB format\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets/Train\\\\Blight'"
     ]
    }
   ],
   "source": [
    "train = get_data('datasets/Train')\n",
    "val = get_data('datasets/Validation')\n",
    "\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feature, label in train:\n",
    "  x_train.append(feature)\n",
    "  y_train.append(label)\n",
    "\n",
    "for feature, label in val:\n",
    "  x_val.append(feature)\n",
    "  y_val.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(224,224,3), kernel_regularizer =tf.keras.regularizers.l2(l=0.01)))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\"\"\"\"\n",
    "model.add(layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\", kernel_regularizer =tf.keras.regularizers.l2( l=0.01)))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "\"\"\"\n",
    "\n",
    "model.add(layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\", kernel_regularizer =tf.keras.regularizers.l2(l=0.01)))\n",
    "model.add(layers.MaxPool2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "initializer = tf.keras.initializers.HeNormal()\n",
    "model.add(layers.Dense(128, kernel_initializer=initializer))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, kernel_initializer=initializer))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1, \n",
    "                                                 save_freq=10*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer = opt, loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \\\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs = 50 , validation_data = (x_val, y_val))\n",
    "\n",
    "predictions = model.predict_classes(x_val)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "print(classification_report(y_val, predictions, target_names = labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6c8cb0d0e74bc9df14118bdcff438f6ae7b86aaded80452eb849caa1428c167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
